---
title: CreelAnalysis from DWG
params:
  location: "Skagit River"
  date_start: "2021-08-14"   
  date_end: "2021-10-31"
  proj_name: "Skagit"
  year_group: "2020-2021"
output:
  html_document:
    fig_caption: yes
    theme: cerulean
    toc: yes
    toc_depth: 3
    toc_float: yes
    code_folding: hide
---

# setup 

```{r setup, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(message = FALSE)

#library(DBI); library(odbc); library(dbplyr)
library(tidyverse)

#base endpoints
dwg <- list(
  event = "https://data.wa.gov/resource/ui95-axtn.csv",
  effort = "https://data.wa.gov/resource/h9a6-g38s.csv",
  interview = "https://data.wa.gov/resource/rpax-ahqm.csv",
  catch = "https://data.wa.gov/resource/6y4e-8ftk.csv",
  gear = "https://data.wa.gov/resource/d2ks-afhz.csv"
)

u <- list()


#### static elements across estimation efforts
## can/should continue to rethink the best way to get this in

# write_lines(
#   2015:2030 %>%
#     map(~c(
#       timeDate::USNewYearsDay(.x), 
#       timeDate::USMLKingsBirthday(.x),
#       timeDate::USPresidentsDay(.x),
#       timeDate::USMemorialDay(.x), 
#       timeDate::USIndependenceDay(.x), 
#       timeDate::USLaborDay(.x),
#       timeDate::USVeteransDay(.x), 
#       timeDate::USThanksgivingDay(.x), 
#       timeDate::timeDate(as.character(timeDate::.nth.of.nday(.x, 11, 5, 4))), #Black Friday
#       timeDate::USChristmasDay(.x)
#     ) |> as.character()
#     ) |>  unlist(),
#   "input_files/dates_holidays_2015_2030.txt")

dates_holidays_2015_2030 <- read_lines("input_files/dates_holidays_2015_2030.txt") |> 
  as.Date(format="%Y-%m-%d")

# Proportional tie in expansion table 
# value of 1 for p_TI means that the entire river section is surveyed during census counts?
# What is "Indirect_TI_Expan" and how it is calculated?
# what are the formatting needs for these data?

# #obviously these need revision & extension to other systems
# #tie_in_indicator: 0 is index/creel, 1 is tie-in/census
# #seems likely that this will need further attention
# #e.g., if different section aggregations for different species within same YearGroup
# bind_rows(
#   read_csv("input_files/lut_02_Crosswalk_Table_for_Index_TieIn_Sections_2019-01-10.csv"),
#   read_csv("input_files/lut_02_Crosswalk_Table_for_Index_TieIn_Sections_2021-02-04.csv")
# ) |> 
#   rename(
#     water_body = StreamName,
#     location = Section.Field
#   ) |> 
#   mutate(tie_in_indicator = if_else(Survey.Type == "Creel", 0, 1)) |> 
#   write_csv("input_files/lut_effort_section_xwalk.csv")

file_names <- list(
  lut_effort_xwalk = "input_files/lut_effort_section_xwalk.csv",
  lut_river_loc = "input_files/lut_02_River.Locations_2019-01-07.csv",
  lut_creel_models = "input_files/lut_02_Creel_Models_2021-01-20.csv",
  lut_census_expansion = "input_files/lut_02_Proportional_Expansions_for_Tie_In_Sections_Kalama_Example.csv" # EB Added proportional TI expansion to list of LUTs
  )


lut <- grep("^lut_", names(file_names), value = T) |> set_names() |> 
  map(~readr::read_csv(file.path(file_names[[.x]])))

```


# get data

The data used are from the `r params$proj_name` project on the `r params$location` between `r params$date_start` and `r params$date_end`.

Further development may include interactive control parameter specification via the GUI: [https://bookdown.org/yihui/rmarkdown/params-knit.html#the-interactive-user-interface]

There is also the option to step through multiple pre-defined control parameters:
[https://bookdown.org/yihui/rmarkdown-cookbook/parameterized-reports.html]

First, get the creel events of interest by building the Socrata API url string and grabbing the data

```{r get_event}
u$event <- URLencode(
  paste0(dwg$event,
         "?water_body=", params$location,
         "&project_name=", params$proj_name,
         "&$where=event_date between '", params$date_start,
         "T12:00:00' and '", params$date_end, "T12:00:00'"
  )
)

event <- read_csv(u$event) |> 
  dplyr::select(creel_event_id, water_body, event_date, tie_in_indicator)

```

Then, get the associated effort and interview data.

```{r get_effort}
u$effort <- URLencode(
  paste0(dwg$effort,
         "?$where=creel_event_id in('",
         paste(event$creel_event_id, collapse = "','"),
         "')&$limit=100000"
  )
)

effort <- read_csv(u$effort)
```

```{r get_interview}
u$interview <- URLencode(
  paste0(dwg$interview,
         "?$where=creel_event_id in('",
         paste(event$creel_event_id, collapse = "','"),
         "')&$limit=100000"
  )
)

interview <- read_csv(u$interview) |> 
  rename(location = interview_location)
```

And finally, the catch data associated with the interviews.

```{r get_catch}
u$catch <- URLencode(
  paste0(dwg$catch,
         "?$where=creel_event_id in('",
         paste(event$creel_event_id, collapse = "','"),
         "')&$limit=100000"
         # "?$where=interview_id in('",
         # paste(interview$interview_id[1:2], collapse = "','"),
         # "')"
  )
)

# catch with redundant post-join columns removed 
catch <- read_csv(u$catch) |> 
  dplyr::select(interview_id, catch_id, species, run, life_stage, fin_mark, fate, fish_count)

```

# QAQC? 

We could include some amount of pre-analysis QAQC...

```{r, eval=FALSE}
identical(nrow(event), nrow(distinct(event, creel_event_id))) #example, likely unnecessary given database structure

#effort$creel_event_id matches event$creel_event_id
distinct(effort, creel_event_id)
setdiff(event$creel_event_id, effort$creel_event_id)
setdiff(effort$creel_event_id, event$creel_event_id)

#but interview$creel_event_id is nested subset of event$creel_event_id
distinct(interview, creel_event_id)
setdiff(event$creel_event_id, interview$creel_event_id)
setdiff(interview$creel_event_id, event$creel_event_id)

#and catch$creel_event_id is nested subset of interview$creel_event_id
setdiff(interview$creel_event_id, catch$creel_event_id)
setdiff(catch$creel_event_id, interview$creel_event_id)

#so catch$creel_event_id is even smaller subset of event$creel_event_id
distinct(catch, creel_event_id)
setdiff(event$creel_event_id, catch$creel_event_id)
setdiff(catch$creel_event_id, event$creel_event_id)

#similarly catch$interview_id is a nested subset of interview$interview_id
setdiff(interview$interview_id, catch$interview_id)
setdiff(catch$interview_id, interview$interview_id)

#event |> head() |> gt::gt()

```

And/or visualization

```{r}
catch |> 
  group_by(species, fin_mark, fate) |> 
  summarise(across(fish_count, list(sum = sum)), .groups = "drop") |> 
  ggplot(aes(fin_mark, fish_count_sum, fill = fate)) + geom_col() +  facet_wrap(~species)
  
```


# wrangle for `stan()`

## dates object

```{r d_days}
#illustrating an example of building an "expanded dates lattice"
#to which any/all observations are attached

(d_days <- tibble(event_date = seq(as.Date(params$date_start, "%Y-%m-%d"), as.Date(params$date_end, "%Y-%m-%d"), by = "day")) %>%
    mutate(
      Day = weekdays(event_date),
      DayType = if_else(Day == "Saturday" | Day == "Sunday" | Day %in% dates_holidays_2015_2030, "Weekend", "Weekday"),
      DayType_num = if_else(str_detect(DayType, "end"),1,0),
      DayL = suncalc::getSunlightTimes(
        date = event_date,
        tz = "America/Los_Angeles",
        lat = lut$lut_river_loc$Lat,
        lon = lut$lut_river_loc$Long,
        keep=c("dawn", "dusk")
        ) |> 
        mutate(DayL = as.numeric(dusk - dawn)) |>
        pluck("DayL")
    ) |> 
    rowid_to_column(var = "day_index"))

#other possibly useful/needed fields that had been created with effort and group/interview data objects
    # Day = weekdays(Date),
    # DayType = if_else(Day == "Saturday" | Day == "Sunday" | Day %in% all_holidays, "Weekend", "Weekday"),
    # Month = format(Date,"%b"), Month.no = as.numeric(format(Date, "%m")),
    # Year = as.numeric(format(Date, "%Y")),
    # Weeknum = as.numeric(format(Date, "%V")),
    # j.date =  as.numeric(format(Date, "%j"))

```

```{r closures}
# Denote fishery closures
#total closed should be responsive rather than declared
#and date declaration can/should be much more concise
#for example something like this...
(closure_dates <- bind_rows(
  tibble(closure_begin = "2021-09-03", closure_end = "2021-09-05", section = "1,2,3"),
  tibble(closure_begin = "2021-09-10", closure_end = "2021-09-12", section = "1,2,3"),
  tibble(closure_begin = "2021-09-17", closure_end = "2021-09-19", section = "1,2"),
  tibble(closure_begin = "2021-09-24", closure_end = "2021-09-26", section = "1,2"),
  tibble(closure_begin = "2021-10-03", closure_end = "2021-10-05", section = "1"),
  tibble(closure_begin = "2021-10-10", closure_end = "2021-10-12", section = "1"),
  tibble(closure_begin = "2021-10-17", closure_end = "2021-10-19", section = "1,2"),
  tibble(closure_begin = "2021-10-24", closure_end = "2021-10-26", section = "1,2")
  ) |>
  rowwise() |>
  mutate(closure_date = paste(seq.Date(as.Date(closure_begin), as.Date(closure_end), by = "day"), collapse = ",")) |>
  separate_rows(closure_date, sep = ",") |>
  separate_rows(section, sep = ","))

# #and total is
# nrow(distinct(closure_dates, closure_date)) #or: length(unique(closure_dates$closure_date))

# EB: need to denote sections that remain open too, can do this with values_fill = 1 within pivot_wider()
# looks like the closure matrix in script 06 is an array of characters
d_days <- d_days |> 
  left_join(
    closure_dates |> 
      select(event_date = closure_date, section) |> 
      mutate(
        event_date = as.Date(event_date),
        closure_code = 0
        ) |> 
      pivot_wider(names_from = section, names_prefix = "section_",
                  values_from = closure_code, values_fill = 1),
    by = "event_date"
  )

#in production, will obviously need to ensure the 0/1 coding is actually appropriate...
d_days <- d_days |> mutate(across(starts_with("section_"), ~replace_na(., 1)))

# #sets up quick QAQC testing
# d_days |> 
#   pivot_longer(names_to = "section", values_to = "close_open", starts_with("section_")) |> 
#   group_by(section) |> 
#   summarise(days_open = sum(close_open))

```

## data from `effort`

### census

```{r effort_census}
#need to LU location to section..
#toy synthetic for demo that needs to go away
lu_section <- distinct(effort, water_body, location) |> #43
  mutate(section = sample(1:3, size = length(location), replace = T))
# #aiming to have this workable...
# lut$lut_effort_xwalk

# EB how is count_num defined for tie-in effort counts in the original code?
#is this a season long count of individual tie-in surveys? 
#count_sequence = 1 for all tie in counts in the database because they are not repeated within a single day 
effort_census <- effort |> 
  filter(
    tie_in_indicator == 1,
    !count_type == "Boats"
    ) |> 
  select(water_body, event_date, location, tie_in_indicator, count_sequence, count_type, count_quantity) |> 
##pending resolution of location name strings in database 
  # left_join(
  #   lut$lut_effort_xwalk |> 
  #     filter(YearGroup == params$year_group)
  #   , by = c("water_body", "location")) |> 
  left_join(lu_section, by = c("water_body", "location")) |>
  left_join(d_days, by = "event_date") |> 
  mutate(
    #angler_type = if_else(count_type == "Boat Anglers", "Boat", "Bank")
    angler_type = str_sub(count_type, 1, 4)
  )


```

### index

```{r effort_index}
# EB Are index counts matched to the nearest individual effort count within a day or to daily mean sum effort count data?

# effort_index contains index counts of vehicles, trailers. 
#Based on KB's comments from KB this should be modified to also include index counts of anglers when they occur in the data 
effort_index <- effort |> 
  filter(tie_in_indicator == 0) |> 
  select(water_body, event_date, location, tie_in_indicator, count_sequence, count_type, count_quantity) |> 
  ##pending resolution of location name strings in database 
  # left_join(
  #   lut$lut_effort_xwalk |> 
  #     filter(YearGroup == params$year_group)
  #   , by = c("water_body", "location")) |> 
  left_join(lu_section, by = c("water_body", "location")) |>
  left_join(d_days, by = "event_date") |> 
  group_by(section, event_date, day_index, count_sequence, count_type) |> 
  summarise(count_quantity_sum = sum(count_quantity), .groups = "drop") |> 
  pivot_wider(names_from = count_type, values_from = count_quantity_sum) |> 
  mutate(across(-c(section:count_sequence), ~replace_na(., 0)))

```

## data from `interview`

Only "index" for interview, by definition.

```{r}
# EB: Seems like species_origin_fate could be another useful control parameter that's set from the get go in the script 
# or species_lifestage_origin_fate where catch of jacks vs. adults is needed (ex. Chinook)

# EB: need to assign anglers to either boat or bank categories 
# trip guided information used in Skagit SH analysis 
# unsure if filling in "unknown" for NA's in trip_guided and trip_status is actually useful 
# use interview time as the fishing_end_time for incomplete trips 
# mutate fishing_time, fishing_end_time - fishing start_time

# EB: join reduced catch table to interview table with "interview_id"

# EB: retain option to filter by target species to assess directed vs. incidental catch?
# EB: how to join catch data to interview data so that catch catch is disinct 
interview_index <- interview |> 
  left_join(catch, by = "interview_id") |>
  left_join(lu_section, by = "location") |> 
  left_join(d_days, by = "event_date") |> 
  mutate(
    angler_type = if_else(boat_used == "No", "Bank", "Boat"),
    trip_guided = case_when(
      trip_guided == "Guided" ~ "Yes",
      trip_guided == "Non-guided" ~ "No",
      trip_guided == "Unknown" ~ "Unknown",
      is.na(trip_guided) ~ "Unknown"),
    trip_status = replace_na(trip_status, "Unknown"),
    fishing_end_time = if_else(is.na(fishing_end_time), interview_time, fishing_end_time),
    angler_hours = round(as.numeric(fishing_end_time - fishing_start_time) / 3600, 2),
    angler_hours_total = angler_count * angler_hours,
    origin = case_when(
      fin_mark == "UM" ~ "W",
      fin_mark == "AD" ~ "H",
      fin_mark == "UNK" ~ "U"),
    origin = replace_na(origin, "U"),
    fate = str_sub(fate, 1,1), #same operation as strsub()
    # fate = case_when(
    #   fate == "Kept" ~ "K",
    #   fate == "Released" ~ "R",
    #   fate == "Unknown" ~ "U"),
    fate = replace_na(fate, "U"),
    species_origin_fate = paste(species, origin, fate, sep = "_")
  ) 

# EB placeholder filter for example of harvested wild coho

TF <- c("Coho_W_K") # TF = target fish. Should this be a contol parameter from the top?

interview_index_TF <- interview_index |> 
  filter(species_origin_fate %in% TF)


```

### Daily interview data from `interview`
```{r}

#total hours creel and total catch sample a per day/gear/section to compare with effort

interview_index_TF_DailySum <- interview_index_TF |>
  group_by(event_date,day_index,section,angler_type) |>
  summarise(
        angler_hours_total_dailysum = sum(angler_hours_total),
  catch_dailysum = sum(fish_count)) |> 
  ungroup() |> 
  filter(angler_hours_total_dailysum > 0)


```

### Interview data filtered to only events with vehicle or trailer counts from `interview`
```{r}

# interview data - angler expansion  KB: interview_sub<-df_interview %>% filter (V_A, T_A, and A_A != NA) ## these variables are used for indirect angler count expansions
# TF = target fish group
# AE = angler expansion 
interview_index_TF_AE <- interview_index_TF |>  
	filter(across(c(vehicle_count, trailer_count), ~ !is.na(.)))

```




## stan_dat

```{r}


stan_dat <- list(
  # Day attributes
  
  # int; number of fishing days; KB: pull from "master_date" DF
	  D <- nrow(d_days) 

	  # int; final number of unique gear/angler types  KB: pull from subsetted angler x-walk? EB: Is this a subset of the data denoting distinct angler types?
	, G <- as.integer(length(unique(interview_index$angler_type))) 
	
	# int; final number of river sections    KB: pull from subsetted section x-walk?
	, S <-  as.integer(length(unique(lu_section$section)))    
	  
	# int; max number of angler effort counts within a sample day KB: max(z$effort$count_sequence)
	, H <- max(effort_index$count_sequence)            
	  
	  # int; number of days/periods KB: right now, model is set up to running as daily (P_n = D) or weekly (P_n = effectively D/7)
	, P_n <- D

	# vec; index denoting daytype (day-type is offset in model)   KB: pull from "master_date" DF (1= weekend, 0 = weekday)
  , w <- d_days$DayType_num

	# int; index denoting fishing day/period      KB: calculate as 1:P_n (not sure why this isn't a vector) EB: what is this? 
	, period <- 1:P_n        
	  
	  # vec; daylength (model offset; assumption)       KB: pull from "master_date" DF
	, L <- d_days$DayL
	
	# mat; index denoting fishery status                          KB: user defined (1=open, 0 = closed; by period/date and section; 0 defined as 1E-6 for model)
	, O <- closure_dates_mat   
	  
	  
	
  # Vehicle index effort counts KB: index_vehicles<-"summ_effort_counts" %>% filter(gear == vehicles, survey == Creel) 
	  
  # int; total number of individual vehicle index effort counts KB: index_vehicles %>% nrow() 
	 , V_n <- effort_index |> 
	    tally() |> 
	    as.integer()

	  # int; index for day/period KB: index_vehicles %>% pull(day/period)
	, day_V <- effort_index |>
	  pull(day_index)
	
	  # int; index for section     KB: index_vehicles %>% pull(section)
	, section_V <- effort_index |>
	  pull(section) 
	  
	  # int; index for count_num    KB: index_vehicles %>% pull(count_num)
	, countnum_V <- effort_index |>    
	  pull(count_sequence)
	  # int; observed # of vehicles  KB: index_vehicles %>% pull(Count)
	, V_I <- effort_index |>
	  pull(`Vehicle Only`)
	  
	
	
	
	# Trailer index effort counts  KB: index_trailers<-"summ_effort_counts" %>% filter(gear == trailers, survey == Creel)
	
	# int; total number of boat trailer index effort counts       KB: index_trailers %>% nrow() 
	, T_n <- effort_index |> 
	    tally() |> 
	    as.integer()
	
  # int; index for day/period         KB: index_trailers %>% pull(day/period)
	, day_T <- effort_index |>
	  pull(day_index) 

  # int; index for section          KB: index_trailers %>% pull(section)
	section_T <- effort_index |>
	, pull(section)

  # int; index for count_num        KB: index_trailers %>% pull(count_num)
	countnum_T <- effort_index |>    
	, pull(count_sequence)

  # int; observed # of boat trailers      KB: index_trailers %>% pull(Count)
	, T_I <- effort_index |>
	  pull(`Trailers Only`)
	       
  
  
	
  # Angler index effort counts                                                     KB: index_anglers<-"summ_effort_counts"     %>% filter(gear == angler_groups, survey == Creel); angler_groups=user defined?
	, A_n =           # int; total number of angler index effort counts            KB: index_anglers %>% nrow()       
	, day_A =         # int; index for day/period                                  KB: index_anglers %>% pull(day/period)  
	, gear_A =        # int; index denoting "gear/angler type"                     KB: index_anglers %>% pull(gear/angler) 
	, section_A =     # int; index for section                                     KB: index_anglers %>% pull(section)
	, countnum_A =    # int; index for count_num                                   KB: index_anglers %>% pull(count_num)
	, A_I =           # int; observed # of anglers                                 KB: index_anglers %>% pull(Count)
  
  
  
  # Census (tie-in) effort counts      KB: TI_anglers<-"summ_effort_counts" %>% filter(survey == "Tie In");

# EB: Not totally sure how to wrangle tie in data to match what's needed in here. Since we want an index of angler type, I left the DF census_index long and filtered out counts of boats
# Need to use KB's (or similar) code chuck to pair census counts to the nearest index count in time
	  
	 # int; total number of angler tie-in effort counts       KB: TI_anglers %>% nrow() 
	, E_n <- effort_census |> 
	    tally() |> 
	    as.integer()          
  
   # int; index denoting day/period                         KB: TI_anglers %>% pull(day/period) 
	, day_E <- effort_census |> 
  pull(day_index)
	
  # int; index denoting "gear/angler type"                  KB: TI_anglers %>% pull(gear/angler)
  , gear_E <- effort_census |> 
  pull(angler_type)        
	
  # int; index for section                                  KB: TI_anglers %>% pull(section)
  , section_E <- effort_census |> 
    pull(section)
	
  # int; index for count_num                                KB: TI_anglers %>% pull(count_num)
  , countnum_E <- effort_census |> 
    pull(count_sequence)   
	
  # int; observed # of anglers                              KB: TI_anglers %>% pull(Count)
  , E_s <- effort_census |> 
    pull(count_quantity)           
  

	# Proportion tie-in expansion mat; proportion of section covered by tie in counts KB: user defined (see "Proportional_Expansions_for_Tie_In_Sections_Kalama_Example"; need to format)
	
	#standat$p_TE<-matrix(1,nrow=standat$G,ncol=standat$S) 
	
	, p_TI <- lut$lut_census_expansion |> 
	  select(
	    Section_Num,
	    p_TI) |>
	  mutate(across(1:2, as.numeric)) |> 
	  as.matrix()
	    
	  
	 # EB: Need to decide at what step in the workflow to filter catch data to species_origin_fate (or other strings including life stage / run). Right now TF object filters interview and catch data to the fish group of interest 
	  
	# interview data - CPUE 
	  
	# int; total number of angler interviews with c & h data   KB: use "summ_interview" DF
	, IntC <- interview_index_TF |> 
	    tally() |> 
	    as.integer()  
	
	# int; index denoting day/period                             KB: summ_interview %>% pull(day/period)
	, day_IntC <- interview_index_TF |> 
  pull(day_index)
	
	# int; index denoting "gear/angler type"                     KB: summ_interview %>% pull(gear/angler) 
	, gear_IntC <- interview_index_TF |> 
	  pull(angler_type)
	  
	  # int; index for section                                     KB: summ_interview %>% pull(section)  
	, section_IntC  <- interview_index_TF |> 
	  pull(section) 
	
	  # int; total catch                                           KB: summ_interview %>% pull(Qty/Count)  
	, c <- interview_index_TF |> 
	  pull(fish_count)          
	  
	# vec; total hours fished   KB: summ_interview %>% pull(Total_Hours) 
  # EB Does Total_Hours refer to fishing time (angler hours) multiplied by the total number of anglers in an                    interviewed party (group_angler_hours)? 
	, h <-  interview_index_TF |> 
	  pull(angler_hours_total)         
	  

	 
	# interview data - Total Effort & Catch Creeled              KB: use "summ_interviewed_effort"
	
	# int; total interviews by sub-groups	                       KB: summ_interviewed_effort %>% nrow()
	, IntCreel <- interview_index_TF_DailySum |>
	    tally() |> 
	    as.integer()        
	
	# int; index denoting day/period                             KB: summ_interviewed_effort %>% pull(day/period)
	, day_Creel <- interview_index_TF_DailySum |>
	    pull(day_index)   
	
	# int; index denoting "gear/angler type"                     KB: summ_interviewed_effort %>% pull(gear/angler)	
	, gear_Creel <- interview_index_TF_DailySum |>
	    pull(angler_type)    
	  
	  # int; index for section                                     KB: summ_interviewed_effort %>% pull(section)
	, section_Creel <- interview_index_TF_DailySum |>
	    pull(section) 		
	  
	  # int; total catch                                           KB: summ_interviewed_effort %>% pull(Qty/Count)
	, C_Creel <- interview_index_TF_DailySum |>
	    pull(catch_dailysum)       
	  
	   # vec; total hours fished                                    KB: summ_interviewed_effort %>% pull(Total_Hours)
	, E_Creel <- interview_index_TF_DailySum |>
	    pull(angler_hours_total_dailysum)       
  
	  
	# interview data - angler expansion  KB: interview_sub<-df_interview %>% filter (V_A, T_A, and A_A != NA) ## these variables are used for indirect angler count expansions
	
	# int; total number of angler interviews where V_A, T_A, A_A were collected KB: interview_sub %>% nrow()
	, IntA <- interview_index_TF_AE |> 
	  tally() |> 
	  as.integer()
	
	  # int; index denoting day/period                             KB: interview_sub %>% pull(day/period)                     	
	, day_IntA <- interview_index_TF_AE |> 
	  pull(day_index)
	  
	  # int; index denoting day/period                             KB: interview_sub %>% pull(gear/angler)        						
	, gear_IntA <- interview_index_TF_AE |> 
	  pull(angler_type)     
	  
	  # int; index denoting day/period                             KB: interview_sub %>% pull(section)   
	, section_IntA <- interview_index_TF_AE |> 
	  pull(section)  
	  
	  # int; total number of vehicles an angler group brought      KB: interview_sub %>% pull(vehicle_count) 
	, V_A <- interview_index_TF_AE |> 
	  pull(vehicle_count)            
	  
	  # int; total number of trailers an angler group brought      KB: interview_sub %>% pull(trailer_count)  
	  
	, T_A <- interview_index_TF_AE |> 
	  pull(trailer_count) 
	  
	  # int; total number of anglers in the groups interviewed     KB: interview_sub %>% pull(angler_count) ## NOTE: this was used above to calculated "Total_Hours" (fished)
	  
	, A_A <- interview_index_TF_AE |> 
	  pull(angler_count)           
	  
)
```


# fit

# results
